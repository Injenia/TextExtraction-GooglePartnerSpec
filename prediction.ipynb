{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "###### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# This Python file uses the following encoding: utf-8\n",
    "from lib.words import not_so_naive_split, reduce_dictionary, sentence_vector, tokenize_doc\n",
    "from lib.pretty_testing import predict_test\n",
    "from keras.models import model_from_json\n",
    "from keras.preprocessing import sequence\n",
    "from lib.untar import ExtractNested\n",
    "from gensim.models import Doc2Vec\n",
    "import lib.text_extraction as te\n",
    "from functools import partial\n",
    "from lib.utils import save_csv\n",
    "\n",
    "import numpy as np\n",
    "import codecs\n",
    "import json\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "###### Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "pdf_names = ['../atti_costitutivi/5122462300001.pdf',\n",
    "             '../files_to_predict/T3LAB-INJENIA_Analisi Preliminare.pdf',\n",
    "             '../files_to_predict/5 Planning Robot.pdf',\n",
    "             '../atti_costitutivi/5122464750001.pdf']\n",
    "\n",
    "labels_map = ['NON COSTITUTIVO', 'COSTITUTIVO']\n",
    "\n",
    "tar_root = '../prova.tar.gz'\n",
    "pdf_folder = '../files_to_predict'\n",
    "png_dir = '../tmp'\n",
    "\n",
    "min_words = 150\n",
    "pages = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "###### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Accetto solo file con dimensione < 5MB\n",
    "def file_filter(f):\n",
    "    return os.path.getsize(str(f.absolute()))<(1024**2*5)\n",
    "    #return f.name.endswith(u'001.pdf') and os.path.getsize(str(f.absolute()))<(1024**2*5)\n",
    "\n",
    "def embed_document(model, doc, permitted_words):\n",
    "    return [sentence_vector(model, sentence, permitted_words) for sentence in doc]\n",
    "\n",
    "def predict_documents_str(filenames, txts, gensim_model, keras_model, permitted_words):\n",
    "    filtered_filenames = [f for f,t in zip(filenames, txts) if (t != None and len(t)>0)]\n",
    "    not_empty_txts =  [t for t in txts if  (t != None and len(t)>0)]\n",
    "    \n",
    "    splitted_txts = [tokenize_doc(txt) for txt in not_empty_txts] \n",
    "    filtered_txts = [list(reduce_dictionary(document, permitted_words)) for document in splitted_txts]\n",
    "    embedded_txts = [embed_document(gensim_model, doc, permitted_words) for doc in filtered_txts]\n",
    "    padded_data = sequence.pad_sequences(embedded_txts, maxlen=200, padding=\"pre\", truncating=\"post\", value=0.0, dtype='float32')\n",
    "    probs = keras_model.predict_proba(padded_data, verbose=0)\n",
    "    return [prob[0] for prob in probs], filtered_filenames\n",
    "\n",
    "def predict_documents_pdf(filenames, gensim_model, keras_model, permitted_words, do_ocr=False):\n",
    "    txts = [te.extract_text(filename, do_ocr, png_dir, min_words, pages) for filename in filenames]\n",
    "    return predict_documents_str(filenames, txts, gensim_model, keras_model, permitted_words)\n",
    "\n",
    "def predict_documents_txt(filenames, gensim_model, keras_model, permitted_words):\n",
    "    txts = [open(filename).read() for filename in filenames]\n",
    "    return predict_documents_str(filenames, txts, gensim_model, keras_model, permitted_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "###### Loading models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "models = {}\n",
    "models['gensim_model'] = Doc2Vec.load('models/gensim_model_5000.d2v')\n",
    "\n",
    "with open('models/keras_model.json') as f:\n",
    "    models['keras_model'] = model_from_json(f.read())\n",
    "models['keras_model'].load_weights(\"models/keras_weights_5000.h5\")\n",
    "\n",
    "with open('first_5000_words.json') as f:\n",
    "    models['permitted_words'] = set(json.load(f))\n",
    "    \n",
    "#predict_pdfs = partial(predict_documents_pdf, gensim_model=gensim_model, keras_model=keras_model, permitted_words=permitted_words)\n",
    "predict_pdfs = partial(predict_documents_pdf, **models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "###### Tar extraction (if needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting '../prova.tar.gz' to 'prova'... Done!\n"
     ]
    }
   ],
   "source": [
    "# Solo se si deve partire da dei tar\n",
    "ExtractNested(tar_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "move_flattened_files(tar_root[:-7], pdf_folder, file_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "pdf_names = [os.path.join(pdf_folder, f) for f in os.listdir(pdf_folder)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "###### With pdf as source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "predictions, filtered_filenames = predict_pdfs(pdf_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5122462300001.pdf                                  \t-\tCOSTITUTIVO  (0.991282)\n",
      "T3LAB-INJENIA_Analisi Preliminare.pdf              \t-\tNON COSTITUTIVO  (0.004446)\n",
      "5 Planning Robot.pdf                               \t-\tNON COSTITUTIVO  (0.003736)\n",
      "5122464750001.pdf                                  \t-\tCOSTITUTIVO  (0.998065)\n"
     ]
    }
   ],
   "source": [
    "for name, pred in zip(filtered_filenames, predictions):\n",
    "    print os.path.basename(name)[:50].ljust(50), '\\t-\\t', labels_map[int(round(pred))], ' (%f)' % pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def basenames(files):\n",
    "    return [os.path.basename(f) for f in files]\n",
    "\n",
    "filt_filenames_set = set(filtered_filenames)\n",
    "labels = [labels_map[int(round(pred))] for pred in predictions]\n",
    "results = list(zip(basenames(filtered_filenames), labels, predictions))\n",
    "\n",
    "not_predicted_pdfs = [pdf for pdf in pdf_names if pdf not in filt_filenames_set]\n",
    "not_predicted_results = ['']*(len(pdf_names)-len(filtered_filenames))\n",
    "all_results = results + list(zip(basenames(not_predicted_pdfs), not_predicted_results, not_predicted_results))\n",
    "headed_results = [('Nome file','Predizione','Output rete')] + all_results\n",
    "\n",
    "save_csv(headed_results, '../predictions.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "###### With txt as source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "txt_names = ['../ocr/scanned_non_costitutivi/3591900710001.txt']\n",
    "\n",
    "pred2, filtered_filenames = predict_documents_txt(txt_names, **models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3591900710001.txt                                  \t-\tNON COSTITUTIVO  (0.043717)\n"
     ]
    }
   ],
   "source": [
    "for name, pred in zip(filtered_filenames, pred2):\n",
    "    print os.path.basename(name)[:50].ljust(50), '\\t-\\t', labels_map[int(round(pred))], ' (%f)' % pred"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
