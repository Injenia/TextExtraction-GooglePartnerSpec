{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Just for experimentation, use train_lstm.py!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# This Python file uses the following encoding: utf-8\n",
    "from keras.models import Sequential\n",
    "from keras.models import model_from_json\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "from keras.preprocessing import sequence\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from lib.pretty_testing import predict_test\n",
    "\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "dataset_file = 'embedded_docs_with_verb.p'\n",
    "model_file = 'models/keras_model.json'\n",
    "model_weights_file = 'models/keras_new_weights_with_verb_es.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# fix random seed for reproducibility\n",
    "np.random.seed(666)\n",
    "\n",
    "\n",
    "# load prepared data\n",
    "with open(dataset_file) as f:\n",
    "    data, labels = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# padding for the rnn\n",
    "padded_data = sequence.pad_sequences(data, maxlen=200,padding=\"pre\", truncating=\"post\", value=0.0, dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# free ram from the original dataset\n",
    "del data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# split dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(padded_data, labels, train_size=0.9, stratify=labels)\n",
    "del padded_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(100, input_shape = (200, 100), return_sequences=True))\n",
    "model.add(LSTM(50))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "\n",
    "'''\n",
    "model = Sequential()\n",
    "model.add(LSTM(100, input_shape = (200, 100)))\n",
    "#model.add(Dropout(0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer=RMSprop(lr=lr), metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "with open(model_file,'w') as f:\n",
    "    f.write(model.to_json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train, epochs=3, batch_size=64, )\n",
    "# Final evaluation of the model\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# serialize weights to HDF5\n",
    "model.save_weights(model_weights_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Test loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 80,501\n",
      "Trainable params: 80,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "with open('models/keras_model.json') as f:\n",
    "    model = model_from_json(f.read())\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "model.load_weights(\"models/keras_new_weights_with_verb_es.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "()\n",
      "Test classification report\n",
      "Accuracy: 0.871552\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      0.80      0.86      1903\n",
      "          1       0.82      0.94      0.88      1904\n",
      "\n",
      "avg / total       0.88      0.87      0.87      3807\n",
      "\n",
      "Test confusion Matrix\n",
      "             non_cost     cost\n",
      "    non_cost   1520.0    383.0\n",
      "        cost    106.0   1798.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [1],\n",
       "       [0],\n",
       "       ..., \n",
       "       [1],\n",
       "       [0],\n",
       "       [0]], dtype=int32)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_test(model, X_test, y_test, [\"non_cost\", \"cost\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 0.02028171],\n",
       "        [ 0.18235052],\n",
       "        [ 0.23812914],\n",
       "        [-0.36414918],\n",
       "        [ 0.21093391],\n",
       "        [ 0.08250543],\n",
       "        [-0.20228331],\n",
       "        [-0.30423039],\n",
       "        [ 0.43490878],\n",
       "        [-0.13503398],\n",
       "        [-0.17565024],\n",
       "        [-0.13670991],\n",
       "        [ 0.31127021],\n",
       "        [ 0.33547062],\n",
       "        [-0.31177467],\n",
       "        [ 0.35819039],\n",
       "        [ 0.41784394],\n",
       "        [-0.40707791],\n",
       "        [ 0.25223097],\n",
       "        [ 0.01939964],\n",
       "        [ 0.34188497],\n",
       "        [-0.16156748],\n",
       "        [-0.36896807],\n",
       "        [ 0.21450199],\n",
       "        [ 0.34476218],\n",
       "        [-0.19144231],\n",
       "        [ 0.08315672],\n",
       "        [ 0.25255978],\n",
       "        [-0.18793416],\n",
       "        [ 0.25187981],\n",
       "        [ 0.23727795],\n",
       "        [ 0.18443318],\n",
       "        [-0.0417008 ],\n",
       "        [-0.04900378],\n",
       "        [ 0.0998246 ],\n",
       "        [ 0.2002323 ],\n",
       "        [ 0.35828298],\n",
       "        [-0.17253509],\n",
       "        [ 0.28414303],\n",
       "        [-0.16518   ],\n",
       "        [ 0.53428423],\n",
       "        [-0.25924474],\n",
       "        [-0.12657176],\n",
       "        [-0.04376576],\n",
       "        [ 0.01440947],\n",
       "        [ 0.02885283],\n",
       "        [ 0.0860679 ],\n",
       "        [-0.05613787],\n",
       "        [ 0.16285311],\n",
       "        [-0.2242392 ],\n",
       "        [ 0.19162026],\n",
       "        [ 0.3265405 ],\n",
       "        [ 0.13604471],\n",
       "        [ 0.32015765],\n",
       "        [ 0.1801012 ],\n",
       "        [ 0.19427018],\n",
       "        [ 0.03716639],\n",
       "        [-0.2606183 ],\n",
       "        [ 0.15225171],\n",
       "        [ 0.09684979],\n",
       "        [-0.11112227],\n",
       "        [-0.2146537 ],\n",
       "        [ 0.39293709],\n",
       "        [ 0.02920622],\n",
       "        [ 0.26526159],\n",
       "        [ 0.23523949],\n",
       "        [-0.22603343],\n",
       "        [ 0.11234383],\n",
       "        [-0.13614529],\n",
       "        [-0.13183871],\n",
       "        [-0.15454179],\n",
       "        [-0.0265037 ],\n",
       "        [-0.19998458],\n",
       "        [-0.33815771],\n",
       "        [-0.36575976],\n",
       "        [-0.25169775],\n",
       "        [-0.15937658],\n",
       "        [-0.09133833],\n",
       "        [-0.05912602],\n",
       "        [-0.0281869 ],\n",
       "        [-0.20600651],\n",
       "        [-0.20787677],\n",
       "        [ 0.02914664],\n",
       "        [ 0.16514958],\n",
       "        [-0.21659684],\n",
       "        [-0.18812419],\n",
       "        [-0.1574354 ],\n",
       "        [ 0.24641734],\n",
       "        [ 0.39519849],\n",
       "        [ 0.21695571],\n",
       "        [ 0.07275988],\n",
       "        [ 0.29917684],\n",
       "        [-0.14111121],\n",
       "        [-0.19372995],\n",
       "        [ 0.00525138],\n",
       "        [ 0.04502369],\n",
       "        [-0.11399326],\n",
       "        [ 0.09193383],\n",
       "        [ 0.04714641],\n",
       "        [-0.06282056]], dtype=float32), array([-0.0459464], dtype=float32)]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = model.layers[1]\n",
    "v.get_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# This Python file uses the following encoding: utf-8\n",
    "from lib.words import tokenize_doc\n",
    "from lib.embedding import reduce_dictionary, sentence_vector\n",
    "from gensim.models import Doc2Vec\n",
    "import lib.text_extraction as te\n",
    "from functools import partial\n",
    "\n",
    "import codecs\n",
    "import json\n",
    "import os\n",
    "import glob\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels_map = ['NON COSTITUTIVO', 'COSTITUTIVO']\n",
    "\n",
    "pdf_folder = '../files_to_predict'\n",
    "pdf_names = glob.glob('../files_to_predict/*')\n",
    "\n",
    "# For OCR...\n",
    "png_dir = '../tmp'\n",
    "min_words = 150\n",
    "pages = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Accetto solo file con dimensione < 5MB\n",
    "def file_filter(f):\n",
    "    return os.path.getsize(str(f.absolute()))<(1024**2*5)\n",
    "    #return f.name.endswith(u'001.pdf') and os.path.getsize(str(f.absolute()))<(1024**2*5)\n",
    "\n",
    "def embed_document(model, doc, permitted_words):\n",
    "    return [sentence_vector(model, sentence, permitted_words) for sentence in doc]\n",
    "\n",
    "def predict_documents_str(filenames, txts, gensim_model, keras_model, permitted_words):\n",
    "    filtered_filenames = [f for f,t in zip(filenames, txts) if (t != None and len(t)>0)]\n",
    "    not_empty_txts =  [t for t in txts if (t != None and len(t)>0)]\n",
    "    \n",
    "    splitted_txts = [tokenize_doc(txt) for txt in not_empty_txts] \n",
    "    filtered_txts = [list(reduce_dictionary(document, permitted_words)) for document in splitted_txts]\n",
    "    embedded_txts = [embed_document(gensim_model, doc, permitted_words) for doc in filtered_txts]\n",
    "    padded_data = sequence.pad_sequences(embedded_txts, maxlen=200, padding=\"pre\", truncating=\"post\", value=0.0, dtype='float32')\n",
    "    probs = keras_model.predict_proba(padded_data, verbose=0)\n",
    "    return [prob[0] for prob in probs], filtered_filenames\n",
    "\n",
    "def predict_documents_pdf(filenames, gensim_model, keras_model, permitted_words, do_ocr=False):\n",
    "    txts = [te.extract_text(filename, do_ocr, png_dir, min_words, pages) for filename in filenames]\n",
    "    return predict_documents_str(filenames, txts, gensim_model, keras_model, permitted_words)\n",
    "\n",
    "def predict_documents_txt(filenames, gensim_model, keras_model, permitted_words):\n",
    "    txts = [open(filename).read() for filename in filenames]\n",
    "    return predict_documents_str(filenames, txts, gensim_model, keras_model, permitted_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "models = {}\n",
    "models['gensim_model'] = Doc2Vec.load('models/gensim_5000_model_with_verb.d2v')\n",
    "models['keras_model'] = model\n",
    "\n",
    "with open('first_5000_words_with_verb_cost.json') as f:\n",
    "    models['permitted_words'] = set(json.load(f))\n",
    "    \n",
    "#predict_pdfs = partial(predict_documents_pdf, gensim_model=gensim_model, keras_model=keras_model, permitted_words=permitted_words)\n",
    "predict_pdfs = partial(predict_documents_pdf, **models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions, filtered_filenames = predict_pdfs(pdf_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3297438520001.pdf                                  \t-\tNON COSTITUTIVO  (0.166989)\n",
      "4908019380001.pdf                                  \t-\tCOSTITUTIVO  (0.956963)\n",
      "3297448050002.pdf                                  \t-\tNON COSTITUTIVO  (0.003005)\n",
      "4907876150001.pdf                                  \t-\tCOSTITUTIVO  (0.970436)\n",
      "4907903520001.pdf                                  \t-\tCOSTITUTIVO  (0.995283)\n",
      "4907874650001.pdf                                  \t-\tCOSTITUTIVO  (0.986870)\n",
      "3296082450001.pdf                                  \t-\tNON COSTITUTIVO  (0.020570)\n",
      "4908013560001.pdf                                  \t-\tCOSTITUTIVO  (0.937010)\n",
      "4907882890001.pdf                                  \t-\tCOSTITUTIVO  (0.982441)\n",
      "4907924550001.pdf                                  \t-\tCOSTITUTIVO  (0.596382)\n",
      "4910203190001.pdf                                  \t-\tCOSTITUTIVO  (0.973300)\n",
      "4907941200001.pdf                                  \t-\tCOSTITUTIVO  (0.959041)\n",
      "4907932630001.pdf                                  \t-\tCOSTITUTIVO  (0.984266)\n",
      "4908003150001.pdf                                  \t-\tCOSTITUTIVO  (0.921671)\n",
      "4907924830001.pdf                                  \t-\tCOSTITUTIVO  (0.989079)\n",
      "4908020300001.pdf                                  \t-\tCOSTITUTIVO  (0.993910)\n",
      "4910194600001.pdf                                  \t-\tCOSTITUTIVO  (0.985993)\n",
      "4907913040001.pdf                                  \t-\tCOSTITUTIVO  (0.872120)\n",
      "3296306190001.pdf                                  \t-\tNON COSTITUTIVO  (0.008274)\n",
      "4907972610001.pdf                                  \t-\tCOSTITUTIVO  (0.988248)\n",
      "3295820790002.pdf                                  \t-\tNON COSTITUTIVO  (0.009369)\n",
      "4907855010001.pdf                                  \t-\tCOSTITUTIVO  (0.712945)\n",
      "3296306190002.pdf                                  \t-\tNON COSTITUTIVO  (0.005439)\n",
      "4908074460001.pdf                                  \t-\tCOSTITUTIVO  (0.776036)\n",
      "3296108720001.pdf                                  \t-\tNON COSTITUTIVO  (0.006499)\n",
      "4907928390001.pdf                                  \t-\tCOSTITUTIVO  (0.993922)\n",
      "3297188780001.pdf                                  \t-\tNON COSTITUTIVO  (0.022734)\n",
      "4908032420001.pdf                                  \t-\tCOSTITUTIVO  (0.974769)\n",
      "5162093290002.pdf                                  \t-\tCOSTITUTIVO  (0.983668)\n",
      "4907938030001.pdf                                  \t-\tCOSTITUTIVO  (0.853346)\n",
      "4907950150001.pdf                                  \t-\tCOSTITUTIVO  (0.933468)\n",
      "4908074200001.pdf                                  \t-\tCOSTITUTIVO  (0.889072)\n",
      "3297155630001.pdf                                  \t-\tNON COSTITUTIVO  (0.354008)\n",
      "4907922110001.pdf                                  \t-\tCOSTITUTIVO  (0.976093)\n",
      "3296581170001.pdf                                  \t-\tNON COSTITUTIVO  (0.024491)\n",
      "4907864950001.pdf                                  \t-\tCOSTITUTIVO  (0.986997)\n",
      "4907913770001.pdf                                  \t-\tCOSTITUTIVO  (0.994332)\n",
      "3296532610001.pdf                                  \t-\tNON COSTITUTIVO  (0.010362)\n",
      "4907990970001.pdf                                  \t-\tCOSTITUTIVO  (0.988104)\n",
      "4907851720001.pdf                                  \t-\tCOSTITUTIVO  (0.729221)\n",
      "3296314320001.pdf                                  \t-\tNON COSTITUTIVO  (0.020407)\n",
      "4908050390001.pdf                                  \t-\tCOSTITUTIVO  (0.819253)\n",
      "4907969870001.pdf                                  \t-\tCOSTITUTIVO  (0.986611)\n",
      "3297182400001.pdf                                  \t-\tNON COSTITUTIVO  (0.003950)\n",
      "3295699350001.pdf                                  \t-\tNON COSTITUTIVO  (0.016294)\n",
      "4908028040001.pdf                                  \t-\tCOSTITUTIVO  (0.993874)\n",
      "3296085790001.pdf                                  \t-\tNON COSTITUTIVO  (0.015612)\n",
      "5162128480002.pdf                                  \t-\tCOSTITUTIVO  (0.985918)\n",
      "4908043600001.pdf                                  \t-\tCOSTITUTIVO  (0.986819)\n",
      "4908018570001.pdf                                  \t-\tCOSTITUTIVO  (0.974729)\n",
      "4907989540001.pdf                                  \t-\tCOSTITUTIVO  (0.992036)\n",
      "3296082450002.pdf                                  \t-\tNON COSTITUTIVO  (0.008084)\n",
      "4908064170001.pdf                                  \t-\tCOSTITUTIVO  (0.840821)\n",
      "4907857640001.pdf                                  \t-\tCOSTITUTIVO  (0.995270)\n",
      "3296089020001.pdf                                  \t-\tNON COSTITUTIVO  (0.006376)\n",
      "4908006150001.pdf                                  \t-\tCOSTITUTIVO  (0.798411)\n",
      "4907971250001.pdf                                  \t-\tCOSTITUTIVO  (0.965693)\n",
      "3295862740001.pdf                                  \t-\tNON COSTITUTIVO  (0.003616)\n",
      "4907944100001.pdf                                  \t-\tCOSTITUTIVO  (0.816334)\n",
      "3296585820001.pdf                                  \t-\tNON COSTITUTIVO  (0.001082)\n",
      "4907923250001.pdf                                  \t-\tCOSTITUTIVO  (0.540892)\n",
      "4907894480001.pdf                                  \t-\tCOSTITUTIVO  (0.941106)\n",
      "3296949670003.pdf                                  \t-\tNON COSTITUTIVO  (0.035590)\n",
      "4908039500001.pdf                                  \t-\tCOSTITUTIVO  (0.884825)\n",
      "4907951200001.pdf                                  \t-\tCOSTITUTIVO  (0.884670)\n",
      "4907902150001.pdf                                  \t-\tCOSTITUTIVO  (0.990689)\n",
      "4907869560001.pdf                                  \t-\tCOSTITUTIVO  (0.939390)\n",
      "4907881040001.pdf                                  \t-\tCOSTITUTIVO  (0.976314)\n",
      "3297438620001.pdf                                  \t-\tNON COSTITUTIVO  (0.040608)\n",
      "3297333600001.pdf                                  \t-\tNON COSTITUTIVO  (0.020091)\n",
      "4908074320001.pdf                                  \t-\tCOSTITUTIVO  (0.973354)\n",
      "4908072640001.pdf                                  \t-\tCOSTITUTIVO  (0.998225)\n",
      "3296466790002.pdf                                  \t-\tNON COSTITUTIVO  (0.005879)\n",
      "4907907730001.pdf                                  \t-\tCOSTITUTIVO  (0.965122)\n",
      "5162128480001.pdf                                  \t-\tNON COSTITUTIVO  (0.022616)\n",
      "3296466790001.pdf                                  \t-\tNON COSTITUTIVO  (0.019925)\n",
      "4907913200001.pdf                                  \t-\tCOSTITUTIVO  (0.992979)\n"
     ]
    }
   ],
   "source": [
    "for name, pred in zip(filtered_filenames, predictions):\n",
    "    print os.path.basename(name)[:50].ljust(50), '\\t-\\t', labels_map[int(round(pred))], ' (%f)' % pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
