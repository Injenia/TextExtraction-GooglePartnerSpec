{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Estrazione Nomi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Da pdf o txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def join_cognomi_articles(words):\n",
    "    articles = set([u'de', u'di', u'du', u'del', u'dell', u'la', u'dei', u'le', \n",
    "                    u'della', u'dall', u'dalla', u'dello', 'degli', 'lo', 'art',\n",
    "                   u'dal', u'dalle'])\n",
    "    found = False\n",
    "    joined_words = []\n",
    "    for word in words:\n",
    "        if not found and word.lower() in articles:\n",
    "            found = True\n",
    "            cur_word = word\n",
    "        elif found:\n",
    "            cur_word += ' '+word\n",
    "            joined_words.append(cur_word)\n",
    "            found = False\n",
    "        else:\n",
    "            joined_words.append(word)\n",
    "    return joined_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#nomi = list(n.strip().lower() for n in open('../extraction/nomi/nomi_asti.txt'))\n",
    "#nomi = set(n.strip().lower() for n in open('../extraction/nomi/nomi_gnorry.txt'))\n",
    "#nomi = set(n.strip().lower() for n in open('../extraction/nomi/nomi_italiani.txt'))\n",
    "#notais = set(n.strip().lower() for n in open('../extraction/nomi/notari.txt'))\n",
    "#cognomi = set(n.strip().lower() for n in open('../extraction/nomi/cognomi.txt'))\n",
    "#cognomi = set(n.strip().lower() for n in open('../extraction/nomi/cognomi_big.txt'))\n",
    "#nomi_cognomi_list = [w for n in open('../extraction/nomi/notari.txt') for w in n.strip().lower().split(' ')]\n",
    "nomi_cognomi_list = [w for n in open('../dictionaries/nomi_notai.txt') for w in n.strip().lower().split(' ')]\n",
    "nomi_cognomi_notai = set(join_cognomi_articles(nomi_cognomi_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "nomi_cognomi_notai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def extract_notaio_from_doc(dirr, is_pdf=False, max=-1):\n",
    "    text = \"\"\n",
    "    for i,f in enumerate(os.listdir(dirr)):\n",
    "        if i == max:\n",
    "            break\n",
    "        if is_pdf and f[-3:] == 'pdf':\n",
    "            text = textract.process(dirr + f).strip()\n",
    "        else: \n",
    "            with open (dirr + f, 'r') as f2:\n",
    "                text = f2.read()\n",
    "        text = wd.replace_evil_dots_and_underscores(text, rep=r' ').replace('\\n',' ').replace(',','')\n",
    "        text = re.sub('\\s+', ' ', text).strip()\n",
    "        found = False\n",
    "        for i,line in enumerate(wd.split_sents(text)):\n",
    "            if found:\n",
    "                break\n",
    "            l = line.strip()\n",
    "            if l != '':\n",
    "                words = l.split(' ')\n",
    "                for word in words:\n",
    "                    if word.lower() == 'me' or word.lower() == 'sottoscritto':\n",
    "                        index = words.index(word)\n",
    "                        print(f, ' '.join(words[index+1:index+6]))\n",
    "                        found = True\n",
    "                        break\n",
    "        if not found:\n",
    "            print('NON TROVATO', '\\t\\t', f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "extract_notaio_from_doc('../extraction/files_to_label/', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "extract_notaio_from_doc('../atti_costitutivi_txt/', False, 500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Dalle frasi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def extract_notaio_from_sentences(doc):\n",
    "    '''\n",
    "    Estrai notaio da un documento.\n",
    "    Arguments:\n",
    "        - doc: il documento (lista di frasi)\n",
    "    Returns:\n",
    "        - lista di nomi, lista di cognomi\n",
    "    '''\n",
    "    #w.lower() in nomi or w.lower() in cognomi or w.lower() in whitelist \\or\n",
    "    whitelist = ['de', 'di'] #, 'dei', 'del', 'della', 'degli', 'delle', 'da', 'dello']\n",
    "    \n",
    "    for frase in doc:\n",
    "        frase = frase.replace('\\n',' ').replace(',','')\n",
    "        frase = re.sub('\\s+', ' ', frase).strip()\n",
    "        if frase != '':\n",
    "            words = re.split('\\W', frase)\n",
    "            #frase.split(' ')\n",
    "            for word in words:\n",
    "                if word.lower() == 'me' or word.lower() == 'sottoscritto' or word.lower() == 'mir':\n",
    "                    index = words.index(word)\n",
    "                    sub = words[index+1:index+6]\n",
    "                    res = ''\n",
    "                    for w in sub:\n",
    "                        if  any((w.lower() in set(x.lower() for x in riga.split(' '))) for riga in notais):\n",
    "                            res += w + ' '\n",
    "                        #if any((w.lower() in set(x.lower() for x in riga.split(' '))) for riga in notais):\n",
    "                        #    res += w + ' '\n",
    "                    res +=  '\\t\\t' +' '.join(sub)   \n",
    "                    return res     \n",
    "                    \n",
    "    return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "for i,f in enumerate(os.listdir('../atti_costitutivi_txt/')):\n",
    "    if i == 500:\n",
    "        break\n",
    "    text = \"\"    \n",
    "    with open ('../atti_costitutivi_txt/' + f, 'r') as f2:\n",
    "        text = f2.read()\n",
    "    sents = wd.sentences_doc(text, rep=r' ')    \n",
    "    res = extract_notaio_from_sentences(sents)\n",
    "    print(i, f, '\\t', res)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "##### Paolo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#paolo\n",
    "\n",
    "def join_apostrophe(words):\n",
    "    joined = ' '.join(words)\n",
    "    rep_d = joined.replace(' d ', ' d\\'').replace(' D ', ' D\\'')\n",
    "    return rep_d.split()\n",
    "\n",
    "def extract_notaio_sent(sentence, notaio_names):\n",
    "    words = join_apostrophe(wd.splitted_words_utf8(sentence))\n",
    "    words = join_cognomi_articles(words)\n",
    "    return [word for word in words if word.lower() in notaio_names and word[0].isupper()]\n",
    "\n",
    "def find_me(words):\n",
    "    lwords = [w.lower() for w in words]\n",
    "    im = -1\n",
    "    arts = set(['me', 'sottoscritto', 'mir'])\n",
    "    for i, word in enumerate(lwords):\n",
    "        if any((w in arts) for w in word.split()):\n",
    "            return i\n",
    "    return im\n",
    "\n",
    "def extract_notaio_name(doc, notaio_names, neigh=5, max_names=3):\n",
    "    words = [w for sent in doc for w in wd.splitted_words_utf8(sent)]\n",
    "    j_words = join_cognomi_articles(join_apostrophe(words))\n",
    "    im = find_me(j_words)\n",
    "    if im >= 0:\n",
    "        m_words = j_words[im+1:im+neigh]\n",
    "    else:\n",
    "        m_words = j_words\n",
    "    found_names = [word for word in m_words if word.lower() in notaio_names and word[0].isupper()]\n",
    "    return uniq_list(found_names)[:max_names]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "for f in glob.glob('../extraction/esempi_descrizioni2/*.pdf'):\n",
    "    txt = te.extract_text(f)\n",
    "    sents = wd.sentences_doc(txt, rep=' ')\n",
    "    name = extract_notaio_name(sents, nomi_cognomi_notai)\n",
    "    print(f.split('/')[-1], name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "txt_dir = '../atti_costitutivi_txt/'\n",
    "l = []\n",
    "for i, f in enumerate(os.listdir(txt_dir)):\n",
    "    txt = open(txt_dir+f).read()\n",
    "    sents = wd.sentences_doc(txt, rep=' ')\n",
    "    name = extract_notaio_name(sents, nomi_cognomi_notai)\n",
    "    l.append(name)\n",
    "    #print(i)\n",
    "    #print(f, ' '.join(name))\n",
    "    #print(txt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "100*sum(1 for n in l if len(n)>1)/len(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "len(os.listdir(txt_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "join_cognomi_articles(u'ciao della maggio uno del pietro caio'.split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Estrazione STATUTO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "import os\n",
    "import re\n",
    "import codecs\n",
    "import textract\n",
    "import lib.words as wd\n",
    "import lib.text_extraction as te\n",
    "import glob\n",
    "import lib.article_numbers as an\n",
    "from shutil import copyfile\n",
    "from lib.utils import uniq_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Sposta tutti i file contenenti uno statuto nella cartella '../statuti'\n",
    "\n",
    "def copy_files_with_statuto(dirr, is_pdf=False, max=-1):\n",
    "    begin_statuto = ['S T A T U T O', 'STATUTO', 'STATUTO DELLA SOCITET', 'FUNZIONAMENTO DELLA SOCIET', 'PATTI DISCIPLINANTI']\n",
    "    \n",
    "    for i,f in enumerate(os.listdir(dirr)):\n",
    "        text = \"\"\n",
    "        if i == 0:\n",
    "            continue\n",
    "        if i == max:\n",
    "            break\n",
    "        if is_pdf and f[-3:] == 'pdf':\n",
    "            try:\n",
    "                text = textract.process(dirr + f).strip()\n",
    "            except:\n",
    "                continue\n",
    "        sents = wd.sentences_doc(text, rep=r' ')    \n",
    "        to_move = False\n",
    "        \n",
    "        for k, frase in enumerate(sents):\n",
    "            if frase.strip() != \"\":\n",
    "                for b in begin_statuto:\n",
    "                    try:\n",
    "                        j = wd.index_ignore_whitespaces(frase, b)\n",
    "                    except:\n",
    "                        print(\"Exception in: \"+frase)\n",
    "                        j = -1\n",
    "                    if j > -1:\n",
    "                        inizio = k\n",
    "                        index = j\n",
    "                        to_move = True\n",
    "                        break\n",
    "                    \n",
    "        if to_move:            \n",
    "            copyfile(str(dirr + f),str(\"../statuti/\" + f))\n",
    "            \n",
    "        print(i, f, to_move)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "copy_files_with_statuto(\"../atti_costitutivi/\", True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def replace_evil_dots(txt, rep=r''):\n",
    "    \"\"\"\n",
    "    Eliminates dots in abbreviations and numbers, in order to split sentences on dots (that really divide sentences).\n",
    "    \"\"\"\n",
    "    no_abbr = re.sub(u'([bcdfghjklmnpqrstvwxyz])\\.(?!\\n)', r'\\1'+rep, txt)\n",
    "    no_nums = re.sub(u'(\\d)\\.(?!\\n)', r'\\1'+rep, no_abbr)\n",
    "    no_nums = re.sub(u'\\.(\\d)', rep + r'\\1', no_nums)\n",
    "    no_maiusc = re.sub(u'([A-Z])\\.(?!\\n)', r'\\1'+rep, no_nums)\n",
    "    return no_maiusc\n",
    "\n",
    "def sentences_doc(doc, rep=r''):\n",
    "    txt = wd.clean_string_not_compressed(doc)\n",
    "    clean_txt = replace_evil_dots(txt, rep=rep)\n",
    "    temp = wd.split_sents_newline(clean_txt) \n",
    "    res = [x.replace(\"<DOT>\",\".\") for x in temp]\n",
    "    #res = [wd.compress_blanks(x.replace(\"<DOT>\",\".\")) for x in temp]\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def replace_evil_dots_statuto(txt, rep=r''):\n",
    "    \"\"\"\n",
    "    Eliminates dots in abbreviations and numbers, in order to split sentences on dots (that really divide sentences).\n",
    "    \"\"\"\n",
    "    no_abbr = re.sub(u'([bcdfghjklmnpqrstvwxyz])\\.(?!\\n)', r'\\1'+rep, txt)\n",
    "    no_nums = re.sub(u'(\\d)\\.(?!\\n)', r'\\1'+rep, no_abbr)\n",
    "    no_nums = re.sub(u'\\.(\\d)', rep + r'\\1', no_nums)\n",
    "    no_maiusc = re.sub(u'([A-Z])\\.(?!\\n)', r'\\1'+rep, no_nums)\n",
    "    return no_maiusc\n",
    "\n",
    "def sentences_doc_statuto(doc, rep=r''):\n",
    "    txt = wd.clean_string_not_compressed(doc)\n",
    "    clean_txt = replace_evil_dots_statuto(txt, rep=rep)\n",
    "    temp = wd.split_sents_newline(clean_txt) \n",
    "    res = [x.replace(\"<DOT>\",\".\") for x in temp]\n",
    "    #res = [wd.compress_blanks(x.replace(\"<DOT>\",\".\")) for x in temp]\n",
    "    return res\n",
    "\n",
    "# Funzione di production, da copiare in article_numbers.py\n",
    "# Prende in ingresso il testo passato solo da Textract e restituisce una stringa con tutto lo statuto\n",
    "def extract_statuto(text):\n",
    "    begin_statuto = ['S T A T U T O', 'STATUTO', 'STATUTO DELLA SOCITET', 'FUNZIONAMENTO DELLA SOCIET', 'PATTI DISCIPLINANTI']\n",
    "    its_a_trap = [\"ATTO COSTITUTIVO\", \"COSTITUZIONE DI SOCIET\", \"si allega\", \"lettera\"]\n",
    "    \n",
    "    inizio = -1\n",
    "    index = -1\n",
    "    fine = -1\n",
    "    \n",
    "    # Just to be sure\n",
    "    text = text.strip()\n",
    "\n",
    "    sents = sentences_doc_statuto(text, rep=r'<DOT>')  \n",
    "\n",
    "    for k, frase in enumerate(sents):\n",
    "        found = False\n",
    "        if index == -1:\n",
    "            for t in its_a_trap:\n",
    "                if wd.index_ignore_whitespaces(frase, t) > -1:\n",
    "                    found = True\n",
    "                    break\n",
    "            if found:\n",
    "                continue\n",
    "\n",
    "            for b in begin_statuto:\n",
    "                j = wd.index_ignore_whitespaces(frase, b)\n",
    "                if j > -1:\n",
    "                    inizio = k\n",
    "                    index = j\n",
    "                    break\n",
    "\n",
    "    if index > -1:     \n",
    "        # end_statuto_text restituisce la prima frase dopo la fine dello statuto\n",
    "        res = an.end_statuto_init_text(wd.clean_string_not_compressed(text), sents[inizio][index:])\n",
    "        if res != '':\n",
    "            res = res + '\\n'\n",
    "            for y, frase2 in reversed(list(enumerate(sents))):\n",
    "                if res in frase2:\n",
    "                    fine = y\n",
    "                    index_fine = frase2.index(res)\n",
    "                    break\n",
    "\n",
    "        for z, fr in enumerate(sents):\n",
    "            if \"RELAZIONE DI STIMA\" in fr:\n",
    "                fine = z\n",
    "                index_fine = fr.index(\"RELAZIONE DI STIMA\")\n",
    "                break\n",
    "\n",
    "    if index > -1 and fine > -1:\n",
    "        to_write = [wd.compress_blanks(s.strip()) for s in sents[inizio+1:fine]]\n",
    "        return(wd.compress_blanks(sents[inizio][index:]) + to_write + wd.compress_blanks(sents[fine][:index_fine]))\n",
    "    elif index > -1 and fine == -1:\n",
    "        to_write = [wd.compress_blanks(s.strip()) for s in sents[inizio+1:]]\n",
    "        return(wd.compress_blanks(sents[inizio][index:]) + to_write)\n",
    "    else:\n",
    "        # Statuto non trovato\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def extract_statuto_from_sentences(dirr, outf, is_pdf=False, max=-1):\n",
    "    begin_statuto = ['S T A T U T O', 'STATUTO', 'STATUTO DELLA SOCITET', 'FUNZIONAMENTO DELLA SOCIET', 'PATTI DISCIPLINANTI']\n",
    "    its_a_trap = [\"ATTO COSTITUTIVO\", \"COSTITUZIONE DI SOCIET\", \"si allega\", \"lettera\"]\n",
    "    \n",
    "    for i,f in enumerate(e for e in os.listdir(dirr) if e[-3:] == \"pdf\"):\n",
    "        text = \"\"\n",
    "        inizio = -1\n",
    "        index, index_fine = -1, -1\n",
    "        fine = -1\n",
    "        #if i == 0:\n",
    "        #    continue\n",
    "        if i == max:\n",
    "            break\n",
    "        if is_pdf and f[-3:] == 'pdf':\n",
    "            text = textract.process(dirr + f).strip()\n",
    "        #sents = [wd.to_utf8(g.strip()) for g in text.split(\"\\n\") if len(g.strip()) > 0]\n",
    "        sents = sentences_doc(text, rep=r'<DOT>')  \n",
    "        print(f)\n",
    "        \n",
    "        for k, frase in enumerate(sents):\n",
    "            found = False\n",
    "            if index == -1:\n",
    "                for t in its_a_trap:\n",
    "                    if wd.index_ignore_whitespaces(frase, t) > -1:\n",
    "                        found = True\n",
    "                        break\n",
    "                if found:\n",
    "                    continue\n",
    "\n",
    "                for b in begin_statuto:\n",
    "                    j = wd.index_ignore_whitespaces(frase, b)\n",
    "                    if j > -1:\n",
    "                        #print (frase, '\\n\\n')\n",
    "                        inizio = k\n",
    "                        index = j\n",
    "                        break\n",
    "                        \n",
    "        if index > -1:     \n",
    "            #print (sents[inizio][index:], '\\n\\n')\n",
    "            # end_statuto_text restituisce la prima frase dopo la fine dello statuto\n",
    "            res = an.end_statuto_init_text(wd.clean_string_not_compressed(text), sents[inizio][index:])\n",
    "            # old func\n",
    "            # res = an.end_statuto_text(wd.to_utf8(text))\n",
    "            if res != '':\n",
    "                res = res + '\\n'\n",
    "                for y, frase2 in reversed(list(enumerate(sents))):\n",
    "                    if res in frase2:\n",
    "                        fine = y\n",
    "                        index_fine = frase2.index(res)\n",
    "                        break\n",
    "            \n",
    "            for z, fr in enumerate(sents):\n",
    "                if \"RELAZIONE DI STIMA\" in fr:\n",
    "                    fine = z\n",
    "                    index_fine = fr.index(\"RELAZIONE DI STIMA\")\n",
    "                    break\n",
    "        \n",
    "\n",
    "        if index > -1 and fine > -1:\n",
    "            to_write = [wd.compress_blanks(s.strip()) for s in sents[inizio+1:fine]]\n",
    "            with codecs.open(outf, 'a', encoding='utf-8') as o:\n",
    "                o.write(f + '\\n\\n' + wd.compress_blanks(sents[inizio][index:])+'\\n'+'\\n'.join(to_write)\n",
    "                        + '\\n' + wd.compress_blanks(sents[fine][:index_fine]) + '\\n\\n\\n\\n\\n')  \n",
    "                \n",
    "        elif index > -1 and fine == -1:\n",
    "            to_write = [wd.compress_blanks(s.strip()) for s in sents[inizio+1:]]\n",
    "            with codecs.open(outf, 'a', encoding='utf-8') as o:\n",
    "                o.write(f + '\\n\\n' + wd.compress_blanks(sents[inizio][index:])+'\\n'+'\\n'.join(to_write) + '\\n\\n\\n\\n\\n')\n",
    "                \n",
    "        else:\n",
    "            with codecs.open(outf, 'a', encoding='utf-8') as o:\n",
    "                o.write(f + '\\n\\n\\n\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# rimuove il file solo se esiste\n",
    "os.path.exists('../statuti/molesti/out.txt') and os.remove('../statuti/molesti/out.txt')\n",
    "extract_statuto_from_sentences('../statuti/molesti/', '../statuti/molesti/out.txt', True, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5089268490001.pdf\n",
      "4918631180001.pdf\n",
      "4986499490001.pdf\n",
      "4991657760001.pdf\n",
      "4952252910001.pdf\n",
      "5097835830001.pdf\n",
      "5062352760001.pdf\n",
      "4918996320001.pdf\n",
      "5050824500001.pdf\n",
      "5000210520001.pdf\n"
     ]
    }
   ],
   "source": [
    "# rimuove il file solo se esiste\n",
    "os.path.exists('../statuti/test/out.txt') and os.remove('../statuti/test/out.txt')\n",
    "extract_statuto_from_sentences('../statuti/test/', '../statuti/test/out.txt', True, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "text = te.extract_text('../statuti/test/5000210520001.pdf')\n",
    "lines = [l.strip() for l in text.split('\\n') if len(l.strip()) > 0]\n",
    "list(enumerate(lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "temp = an.matches_list(lines)\n",
    "an.filter_matches_errors(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#print('\\n\\n\\n'.join(s.replace('\\n','< >') for s in sentences_doc(text, rep=r'<DOT>')))\n",
    "#sentences_doc(text, rep=r'<DOT>')\n",
    "print (text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
