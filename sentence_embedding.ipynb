{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Embedding delle Frasi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Solo per sperimentazione, usa embedding.py!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# This Python file uses the following encoding: utf-8\n",
    "from gensim import utils\n",
    "from gensim.models.doc2vec import LabeledSentence\n",
    "from gensim.models import Doc2Vec\n",
    "from lib import embedding as em\n",
    "from lib.parallelize import parallelize\n",
    "\n",
    "import numpy as np\n",
    "import re\n",
    "import string\n",
    "import os\n",
    "import json\n",
    "import operator\n",
    "import pickle\n",
    "\n",
    "import random\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "###### Creazione del dataset come sottoinsieme bilanciato dei documenti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "csv_filename = '../atti2.csv'\n",
    "model_filename = '../models/gensim_model.d2v'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py:2717: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(csv_filename, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19033"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size_nc = len(df.loc[df['label'] == 'non_costitutivo'].groupby('filename'))\n",
    "size_nc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Permitted words only on costitutivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "gb = df.loc[df['label'] == 'costitutivo'].groupby('filename')\n",
    "cost_df = pd.concat([ gb.get_group(group) for i,group in enumerate( gb.groups) if i < size_nc ])\n",
    "del gb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "del df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "permitted_words = [e[0] for e in em.first_n_words([s.split() for s in cost_df[\"sentence\"]], 5000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "with open(\"../dictionaries/first_5000_words_with_verb_cost.json\", 'w') as o:\n",
    "    json.dump(permitted_words, o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "with open(\"../dictionaries/first_5000_words_with_verb_cost.json\") as o:\n",
    "    permitted_words = set(json.load(o))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Balancing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "grouped = df.loc[df['label'] == 'costitutivo'].groupby(df[\"filename\"])\n",
    "dfs = [g[1] for g in list(grouped)[:size_nc]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "grouped_nc = df.loc[df['label'] == 'non_costitutivo'].groupby(df[\"filename\"])\n",
    "dfs_nc = [g[1] for g in list(grouped_nc)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_balanced = pd.concat(dfs + dfs_nc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "del df\n",
    "del grouped\n",
    "del dfs\n",
    "del grouped_nc\n",
    "del dfs_nc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "###### Creazione degli embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def build_dictionary(sentences):\n",
    "    d = dict()\n",
    "    index = 0\n",
    "    for sentence in sentences:\n",
    "        for word in sentence:\n",
    "            if not word in d:\n",
    "                d[word] = index\n",
    "                index += 1\n",
    "    return d\n",
    "\n",
    "def word_counts(sentences):\n",
    "    d = dict()\n",
    "    for sentence in sentences:\n",
    "        for word in sentence:\n",
    "            if not word in d:\n",
    "                d[word] = 1\n",
    "            else:\n",
    "                d[word] += 1\n",
    "    return d\n",
    "\n",
    "def rev_dict(d):\n",
    "    rd = dict()\n",
    "    for w,i in d.items():\n",
    "        rd[i] = w\n",
    "    return rd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Sentence iterator for building the gensim model\n",
    "\n",
    "def iter_sentences(sents):\n",
    "    i = 0\n",
    "    for line in sents:\n",
    "        yield LabeledSentence(line, ['SENT_%s' % i])\n",
    "        i += 1\n",
    "\n",
    "# Modello dell'embedding\n",
    "\n",
    "def build_embedding(sentences, epochs = 10):\n",
    "    if os.path.exists(model_filename):\n",
    "        model = Doc2Vec.load(model_filename)\n",
    "    else:\n",
    "        model = Doc2Vec(min_count=1, window=10, size=100, sample=1e-5, negative=5, workers=2)\n",
    "        model.build_vocab(sentences)\n",
    "        print 'Vocabulary built'\n",
    "        #for epoch in range(5):\n",
    "        #    print 'Epoch', epoch\n",
    "        model.train(sentences, model.corpus_count, epochs = epochs)\n",
    "        model.save(model_filename)\n",
    "        print 'Model saved'\n",
    "    return model\n",
    "\n",
    "def first_n_words(dictionary, n):\n",
    "    wc = word_counts(s.split() for s in pd_sentences)\n",
    "    sorted_wc = sorted(wc.items(), key=operator.itemgetter(1))\n",
    "    return set(reversed([x[0] for x in sorted_wc[-n:]]))\n",
    "\n",
    "def substitute_word(word, permitted_words, unknown = 'UNK'):\n",
    "    return word if word in permitted_words else unknown\n",
    "\n",
    "def reduced_sentence(sentence, permitted_words):\n",
    "    return [substitute_word(word, permitted_words) for word in sentence]\n",
    "\n",
    "def reduce_dictionary(sentences, permitted_words, min_words=2):\n",
    "    for sentence in sentences:\n",
    "        new_sentence = reduced_sentence(sentence, permitted_words)\n",
    "        if len(new_sentence) >= min_words:\n",
    "            yield new_sentence\n",
    "            \n",
    "def sentence_vector(model, sentence, permitted_words):\n",
    "    return model.infer_vector(reduced_sentence(sentence.split(' '), permitted_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "d = build_dictionary(s.split() for s in pd_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "len(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#first_10000_words = first_n_words(d, 10000)\n",
    "first_5000_words = first_n_words(d, 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "wc = word_counts(s.split() for s in pd_sentences)\n",
    "sorted_wc = sorted(wc.items(), key=operator.itemgetter(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "sorted_wc[-8000:-7500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "with open('reduced_dictionary.json','w') as f:\n",
    "    json.dump(list(first_5000_words), f)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "with open('first_5000_words.json','w') as f:\n",
    "    json.dump(list(first_5000_words), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "first_5000_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "filtered_sentences = reduce_dictionary((s.split() for s in pd_sentences), first_5000_words)\n",
    "filtered_sentences_list = list(filtered_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Definizione del modello\n",
    "\n",
    "model = build_embedding(list(iter_sentences(filtered_sentences_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "model.most_similar('atto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Esempio di sentence vector\n",
    "\n",
    "sv = sentence_vector(model, pd_sentences[551068], first_10000_words)\n",
    "sv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "###### Costruzione del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def build_dataset(model, df, permitted_words):\n",
    "    filename = \"\"\n",
    "    docs = []\n",
    "    labels = []\n",
    "    curdoc = []                  # lista delle frasi del documento corrente\n",
    "    for i in xrange(len(df)):\n",
    "        row = df.iloc[i] \n",
    "        if filename == \"\":\n",
    "            filename = row[\"filename\"]\n",
    "            labels.append(row[\"label\"])\n",
    "            \n",
    "        embedding = sentence_vector(model, row['sentence'], permitted_words)\n",
    "        if filename == row[\"filename\"]:\n",
    "            curdoc.append(embedding)\n",
    "        else:\n",
    "            print \"%s with len: %d\" % (filename, len(curdoc))\n",
    "            docs.append(curdoc)\n",
    "            curdoc = [embedding]\n",
    "            labels.append(row[\"label\"])\n",
    "            filename = row['filename']\n",
    "    if len(curdoc)>0:\n",
    "        docs.append(curdoc)\n",
    "    return docs, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "docs, labels = build_dataset(model, df_balanced, first_10000_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "label_map = {'costitutivo':1, 'non_costitutivo':0}\n",
    "labels_n = [label_map[l] for l in labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "with open(\"../datasets/embedded_docs.p\", \"w\") as fout:\n",
    "    pickle.dump([docs, labels_n], fout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### New embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "model =  Doc2Vec.load('../models/gensim_5000_model_with_verb.d2v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def group_to_list_label(g):\n",
    "    label = next(iter(g[\"label\"]))\n",
    "    sents = list(g[\"sentence\"])\n",
    "    return sents, label\n",
    "\n",
    "def embed_document_p(doc, model, permitted_words):\n",
    "    return [sentence_vector(model, sentence, permitted_words) for sentence in doc]\n",
    "\n",
    "parallel_embed_document = parallelize(embed_document_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def build_dataset2(model, df, permitted_words):\n",
    "    l = [x for x in df.groupby(\"filename\").apply(group_to_list_label)]\n",
    "    docs = [e[0] for e in l]\n",
    "    labels = [e[1] for e in l]\n",
    "    print(\"Starting to embed\")\n",
    "    embedded_docs = parallel_embed_document(docs, model, permitted_words)\n",
    "    return embedded_docs, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "docs, labels = build_dataset2(model, df_balanced, permitted_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
