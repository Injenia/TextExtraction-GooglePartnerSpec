{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "from gensim.models import Doc2Vec, Word2Vec\n",
    "import lib.text_extraction as te\n",
    "from functools import partial\n",
    "from lib.parallelize import parallelize\n",
    "from collections import OrderedDict\n",
    "import lib.embedding as em\n",
    "import lib.words as wd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import operator\n",
    "import codecs\n",
    "import math\n",
    "import json\n",
    "import csv\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Sentencing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "test_dir = '../extraction/esempi_descrizioni/'\n",
    "\n",
    "def list_dir(d):\n",
    "    return [os.path.join(test_dir, f) for f in os.listdir(d)]\n",
    "\n",
    "filenames = os.listdir(test_dir)\n",
    "full_filenames = list_dir(test_dir)\n",
    "\n",
    "txts = [te.extract_text(f, do_ocr=True, pages=-1) for f in full_filenames]\n",
    "\n",
    "#txts = parallelize(te.extract_text)(full_filenames, do_ocr=True, pages=-1) #Doesn't work with do_ocr=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "for i, txt in zip(filenames, txts):\n",
    "    print('Documento ', i)\n",
    "    print(txt[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "extracted_txts_dir = '../extraction/esempi_extracted/'\n",
    "\n",
    "for fn, txt in zip(filenames, txts):\n",
    "    utxt = wd.to_utf8(txt)\n",
    "    with codecs.open(os.path.join(extracted_txts_dir, fn[:-3])+'txt', 'w', encoding='utf-8') as o:\n",
    "        o.write(utxt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "sentences_dir = '../extraction/esempi_sentences/'\n",
    "\n",
    "sentences = [wd.sentences_doc(txt) for txt in txts]\n",
    "\n",
    "for fn, txt in zip(filenames, sentences):\n",
    "    with codecs.open(os.path.join(sentences_dir, fn[:-3])+'txt', 'w', encoding='utf-8') as o:\n",
    "        o.write('\\n'.join(s.replace('\\n',' ').strip() for s in txt if s.strip()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Saving sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "sentenced_txts = [wd.sentences_doc(txt) for txt in txts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def sentence_label_csv_empty(filenames, sentenced_txts, csv_out, sep=u'\\t', min_len=10):\n",
    "    csv_out.write(sep.join([u'filename',u'sent_index',u'sentence',u'label']) + u'\\n')\n",
    "    for f, sents in zip(filenames, sentenced_txts):\n",
    "        for i, sent in enumerate(sents):\n",
    "            clean_sent = sent.replace(sep,u'').replace(u'\\n',u' ').strip()\n",
    "            if len(clean_sent)>=min_len:\n",
    "                csv_out.write(sep.join([u'{}',u'{}',u'{}',u'non_rilevante']).format(f,i,clean_sent)+u'\\n')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "csv_filename = '../extraction/sentence_labels.csv'\n",
    "with codecs.open(csv_filename, 'w', encoding='utf-8') as csv_out:\n",
    "    sentence_label_csv_empty(os.listdir(test_dir), sentenced_txts, csv_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(csv_filename, sep='\\t', encoding='utf-8', quoting=csv.QUOTE_NONE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labelled_filename = '../extraction/sentence_manual_labels.csv'\n",
    "dfm = pd.read_csv(labelled_filename, sep='\\t', encoding='utf-8', quoting=csv.QUOTE_NONE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Experiments on labelled sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def cosine_similarity(a,b):\n",
    "    return np.dot(a,b)/(np.linalg.norm(a)*np.linalg.norm(b))\n",
    "\n",
    "def splitted_words_lower(sentences):\n",
    "    return [[w.lower() for w in wd.splitted_words_utf8(s)] for s in sentences]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "labeled_csv_filename = '../extraction/sentence_manual_labels3.csv'\n",
    "\n",
    "ldf = pd.read_csv(labeled_csv_filename, sep='\\t', encoding='utf-8', quoting=csv.QUOTE_NONE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "poteri = ldf.loc[ldf['label'] == 'poteri']['sentence']\n",
    "gestione = ldf.loc[ldf['label'] == 'gestione']['sentence']\n",
    "finanziario =  ldf.loc[ldf['label'] == 'finanziario']['sentence']\n",
    "clausole = ldf.loc[ldf['label'] == 'clausola']['sentence']\n",
    "\n",
    "splits = {}\n",
    "splits['poteri'] = splitted_words_lower(poteri)\n",
    "splits['gestione'] = splitted_words_lower(gestione)\n",
    "splits['finanziario'] = splitted_words_lower(finanziario)\n",
    "splits['clausola'] = splitted_words_lower(clausole)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def word_counts(sentences):\n",
    "    d = dict()\n",
    "    for sentence in sentences:\n",
    "        for word in sentence:\n",
    "            if not word in d:\n",
    "                d[word] = 1\n",
    "            else:\n",
    "                d[word] += 1\n",
    "    return d\n",
    "\n",
    "def first_n_words(sentences, n):\n",
    "    wc = word_counts(sentences)\n",
    "    sorted_wc = sorted(wc.items(), key=operator.itemgetter(1))\n",
    "    return list(reversed([x for x in sorted_wc[-n:]]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "first_n_words(split_poteri, 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Tf Idf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def tf(word, sentence):\n",
    "    '''Term frequency in the sentence'''\n",
    "    return sum(1 for w in sentence if w == word)/len(sentence)\n",
    "\n",
    "def idf(word, documents):\n",
    "    '''Inverse document frequency'''\n",
    "    D = len(documents)\n",
    "    den = 1+sum(1 for sentence in documents if word in sentence)\n",
    "    return math.log(D/den)\n",
    "\n",
    "def idf_memo(documents):\n",
    "    '''Defines a memoized version of idf with the given set of documents'''\n",
    "    word_idf = {}\n",
    "    def memoized_idf(word):\n",
    "        if not word in word_idf:\n",
    "            word_idf[word] = idf(word, documents)\n",
    "        return word_idf[word]\n",
    "    return memoized_idf\n",
    "\n",
    "def tf_idf(word, sentence, sentences):\n",
    "    '''Simple tf-idf index'''\n",
    "    return tf(word, sentence)*idf(word, sentences)\n",
    "\n",
    "def tf_idf_memo(documents):\n",
    "    '''Defines a memoized version of tf-idf with the given set of documents'''\n",
    "    idf_memoized = idf_memo(documents)\n",
    "    def tf_idf_memoized(word, sentence):\n",
    "        return tf(word, sentence)*idf_memoized(word)\n",
    "    return tf_idf_memoized\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# On all sentences\n",
    "split_sentences = [[w.lower() for w in wd.splitted_words_utf8(s)] for s in ldf['sentence']]\n",
    "tf_idf_memoized = tf_idf_memo(split_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sorted_tfidf_words(splitted_sentences , tf_idf_memoized):\n",
    "    words = set(word for sent in splitted_sentences for word in sent)\n",
    "    words_mean_tfidf = [(word, np.mean([tf_idf_memoized(word, s) for s in splitted_sentences])) for word in words]\n",
    "    return sorted(words_mean_tfidf, key=operator.itemgetter(1), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sorted_words = {k:sorted_tfidf_words(v, tf_idf_memoized) for k,v in splits.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def print_parole_tf_idf(sorted_words, n = -1):\n",
    "    print(u'{:20}\\t{:20}\\n'.format(u'parola',u'mean tf-idf'))\n",
    "    if n < 0:\n",
    "        n = len(sorted_words)\n",
    "    for w, score in sorted_words[:n]:\n",
    "        print(u'{:20}\\t{:1.4f}'.format(w,score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clausola:\n",
      "parola              \tmean tf-idf         \n",
      "\n",
      "recesso             \t0.0541\n",
      "diritto             \t0.0317\n",
      "socio               \t0.0300\n",
      "il                  \t0.0274\n",
      "esclusione          \t0.0249\n",
      "trasferimento       \t0.0249\n",
      "esercitato          \t0.0247\n",
      "prelazione          \t0.0240\n",
      "dalla               \t0.0227\n",
      "che                 \t0.0211\n",
      "\n",
      "poteri:\n",
      "parola              \tmean tf-idf         \n",
      "\n",
      "poteri              \t0.1247\n",
      "ordinaria           \t0.0654\n",
      "straordinaria       \t0.0654\n",
      "amministrativo      \t0.0481\n",
      "organo              \t0.0431\n",
      "amministrazione     \t0.0422\n",
      "ampi                \t0.0393\n",
      "tutti               \t0.0375\n",
      "atti                \t0.0365\n",
      "i                   \t0.0310\n",
      "\n",
      "gestione:\n",
      "parola              \tmean tf-idf         \n",
      "\n",
      "assemblea           \t0.0484\n",
      "controllo           \t0.0311\n",
      "organo              \t0.0292\n",
      "rappresentanza      \t0.0288\n",
      "l                   \t0.0268\n",
      "amministratore      \t0.0267\n",
      "31                  \t0.0264\n",
      "dicembre            \t0.0254\n",
      "esercizi            \t0.0242\n",
      "presidente          \t0.0241\n",
      "\n",
      "finanziario:\n",
      "parola              \tmean tf-idf         \n",
      "\n",
      "utili               \t0.1142\n",
      "ripartizione        \t0.0789\n",
      "riserva             \t0.0509\n",
      "non                 \t0.0487\n",
      "a                   \t0.0477\n",
      "quote               \t0.0449\n",
      "legale              \t0.0404\n",
      "vincoli             \t0.0386\n",
      "farsi               \t0.0377\n",
      "netti               \t0.0371\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for k,v in sorted_words.items():\n",
    "    print('{}:'.format(k))\n",
    "    print_parole_tf_idf(v, 10)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "most_relevant_poteri_words = OrderedDict(sorted_words['poteri']) #[:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def score_sentence_frequency(sentence, most_relevant_words):\n",
    "    '''cosine distance between frequency of words in sentence and the most relevant words tf-idf'''\n",
    "    counts = OrderedDict((w, 0) for w in most_relevant_words.keys())\n",
    "    for w in sentence:\n",
    "        if w in counts:\n",
    "            counts[w] += 1\n",
    "    l = len(sentence)\n",
    "    frequencies = [v/l for v in counts.values()]\n",
    "    if np.linalg.norm(frequencies) == 0 or np.linalg.norm(most_relevant_words.values()) == 0:\n",
    "        return 0\n",
    "    return cosine_similarity(np.array(frequencies), np.array(most_relevant_words.values())) \n",
    "    \n",
    "def score_sentence_tf_idf(sentence, most_relevant_words, tf_idf_memoized):\n",
    "    '''cosine distance between tf-idf of words in sentence and the most relevant words tf-idf'''\n",
    "    tfidfs = OrderedDict((w, 0) for w in most_relevant_words.keys())\n",
    "    for w in sentence:\n",
    "        tfidfs[w] = tf_idf_memoized(w, sentence)\n",
    "    if np.linalg.norm(tfidfs.values()) == 0 or np.linalg.norm(most_relevant_words.values()) == 0:\n",
    "        return 0\n",
    "    l = min(len(tfidfs), len(most_relevant_words))\n",
    "    return cosine_similarity(np.array(tfidfs.values())[:l], np.array(most_relevant_words.values())[:l])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.32379071659198394,\n",
       " 0.59740762729606212,\n",
       " 0.30764712135823419,\n",
       " 0.60669772109575748,\n",
       " 0.21387284004817195,\n",
       " 0.35332138094439314,\n",
       " 0.6415739240343038,\n",
       " 0.32936917946886574,\n",
       " 0.32770262920227322,\n",
       " 0.37422635942514959,\n",
       " 0.52949653034409405,\n",
       " 0.32299077118895225,\n",
       " 0.35812915982090548,\n",
       " 0.40768696066110732,\n",
       " 0.30846815664977711,\n",
       " 0.19185333870688018,\n",
       " 0.45297720514993728,\n",
       " 0.3143652635965582,\n",
       " 0.4881908718502061,\n",
       " 0.42818052651950456,\n",
       " 0.50531713756295205,\n",
       " 0.56962872622413585,\n",
       " 0.51276472884112589,\n",
       " 0.39540870535544703,\n",
       " 0.5846872280416926,\n",
       " 0.61897238299021196]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[score_sentence_tf_idf(split, OrderedDict(sorted_words['poteri']), tf_idf_memoized) for split in splits['poteri']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15789826365293538"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_sentence_tf_idf(split_sentences[1432], OrderedDict(sorted_words['poteri']), tf_idf_memoized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Embeddings test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "txts_tokenized = [wd.tokenize_doc(txt) for txt in txts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "reduced_dictionary_filename = 'first_5000_words.json'\n",
    "with open(reduced_dictionary_filename) as f:\n",
    "    reduced_dictionary = set(json.load(f))\n",
    "\n",
    "gensim_model_filename = 'models/gensim_model_5000.d2v'\n",
    "gensim_model = Doc2Vec.load(gensim_model_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "embeddings = [em.embed_document(gensim_model, txt, reduced_dictionary) for txt in txts_tokenized]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "sv = partial(em.sentence_vector, model=gensim_model, permitted_words=reduced_dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "p1 = u'All\\'organo amministrativo sono conferiti i più ampi poteri, sia per la gestione ordinaria che straordinaria della Società'\n",
    "p2 = u'ARTICOLO 19 - POTERI DELL\\'ORGANO AMMINISTRATIVO 191 L\\'organo amministrativo ha tutti i poteri di ordinaria e straordinaria amministrazione'\n",
    "cosine_similarity(sv(sentence=p1.lower()),sv(sentence=p2.lower())) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "mean_cosines_poteri = [np.mean([cosine_similarity(sv(sentence=split_poteri[i]), sv(sentence=split_poteri[j]))\n",
    "                               for i in range(len(split_poteri)) if i != j])\n",
    "                                   for j in range(len(split_poteri))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mean_cosines_poteri"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Word2Vec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "sentences_tokenized = [sent for doc in txts_tokenized for sent in doc] #i should reduce the dictionary also"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "w2v = Word2Vec(sentences_tokenized, size=100, window=5, min_count=5, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "w2v.wv['costitutivo']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "cosine_similarity(w2v.wv['atto'], w2v.wv['costitutivo'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "w2v.most_similar('poteri')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "w2v.most_similar(positive=['atto','costitutivo'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
